{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7116116d",
   "metadata": {},
   "source": [
    "# Dataset Preparation File\n",
    "\n",
    "In order to replicate the test that was performed in my Master's report, this file contains the code necessary to fully filter, format, and export the AudioCaps dataset. This Jupyter Notebook can be used for any dataset in severed parquet files, as long as they start in a /data/ folder at the same directory level as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7434e1f0",
   "metadata": {},
   "source": [
    "Prior to running this file, ensure that the python package \"pandas\" is installed and AudioCaps parquet files are downloaded from https://huggingface.co/datasets/OpenSound/AudioCaps?clone=true and left inside the repository's data folder. The current prepareDataset.ipynb file should be inside the same folder as the /data/ folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "677ba33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9518b0f",
   "metadata": {},
   "source": [
    "First, we test to see that we can access our dataset and we know how many dog / cat files exist within the first file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2a02bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 7)\n",
      "(5, 7)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet('data/test-00000-of-00041.parquet')\n",
    "\n",
    "filtered_df = df[df[\"caption\"].str.contains(\"Dog\") | \n",
    "                 df[\"caption\"].str.contains(\"dog\") | \n",
    "                 df[\"caption\"].str.contains(\"Cat\") | \n",
    "                 df[\"caption\"].str.contains(\"cat\")]\n",
    "\n",
    "print(df.shape)\n",
    "print(filtered_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe3aa8d",
   "metadata": {},
   "source": [
    "If this returns sensible values (e.g. (108, 7) and (5, 7)), then the next block is executed to perform this filtration on all files in the data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e390b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"filtered\", exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(\"data\"):\n",
    "    df = pd.read_parquet(os.path.join(\"data\", filename))\n",
    "    filtered_df = df[df[\"caption\"].str.contains(\"Dog\") |\n",
    "                     df[\"caption\"].str.contains(\"dog\") |\n",
    "                     df[\"caption\"].str.contains(\"Cat\") |\n",
    "                     df[\"caption\"].str.contains(\"cat\")]\n",
    "    filtered_df.to_parquet(os.path.join(\"filtered\", filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48008904",
   "metadata": {},
   "source": [
    "All of the filtered files are finally combined into one dataset, but the memory this consumes requires this to be performed only a few files at a time. The next block combines every file in the /filtered/ folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5333f53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_count = len(os.listdir(\"filtered\"))\n",
    "\n",
    "while(file_count > 5):\n",
    "    file_list = os.listdir(\"filtered\")  \n",
    "    groups_count = int(file_count / 5)\n",
    "    for i in range(groups_count):\n",
    "        dfs = []\n",
    "        for j in range(5):\n",
    "            # filename = \"filtered/{:05d}-of-{:05d}\".format(i*5+j,int(groups_count))\n",
    "            filename = os.path.join(\"filtered\", file_list[i*5 + j])\n",
    "            dfs.append(pd.read_parquet(filename))\n",
    "            \n",
    "        fiveRows = pd.concat(dfs).reset_index(drop=True)\n",
    "        fiveRows.to_parquet(os.path.join(\"filtered\", \"combined-{:05d}-of-{:05d}.parquet\".format(i, groups_count)))\n",
    "        \n",
    "        for j in range(5):\n",
    "            os.remove(os.path.join(\"filtered\", file_list[i*5 + j]))\n",
    "        \n",
    "    file_count = len(os.listdir(\"filtered\"))\n",
    "\n",
    "dfs = []\n",
    "file_list = os.listdir(\"filtered\")\n",
    "for i in range(len(file_list)):\n",
    "    filename = os.path.join(\"filtered\", file_list[i])\n",
    "    dfs.append(pd.read_parquet(filename))\n",
    "    \n",
    "finalCombination_df = pd.concat(dfs).reset_index(drop=True)\n",
    "finalCombination_df.to_parquet(\"filtered/combined.parquet\")\n",
    "\n",
    "for i in range(len(file_list)):\n",
    "    os.remove(os.path.join(\"filtered\", file_list[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45129e82",
   "metadata": {},
   "source": [
    "Finally, the combined dataset is formatted into the correct columns, exported as a metadata.csv file and .wav files, and zipped for use in the interface. All three of these steps are performed in the following block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27264116",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORT_FOLDER_NAME = \"exported-dataset\"\n",
    "os.makedirs(os.path.join(EXPORT_FOLDER_NAME, \"data\"), exist_ok=True)\n",
    "\n",
    "# Format dataset\n",
    "formatted_df = pd.DataFrame({\n",
    "    'audio': './data/' + finalCombination_df['audio.path'],\n",
    "    'caption': finalCombination_df['caption']\n",
    "})\n",
    "\n",
    "# Export as metadata.csv\n",
    "formatted_df.to_csv(os.path.join(EXPORT_FOLDER_NAME, \"metadata.csv\"), index=False)\n",
    "\n",
    "# Export .wavs\n",
    "for index, row in finalCombination_df.iterrows():\n",
    "    with open(os.path.join(EXPORT_FOLDER_NAME, \"data\", row['audio.path']), 'wb') as f:\n",
    "        f.write(row['audio.bytes'])\n",
    "\n",
    "# Zip\n",
    "shutil.make_archive(EXPORT_FOLDER_NAME, \"zip\", EXPORT_FOLDER_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bb87ed",
   "metadata": {},
   "source": [
    "This zip file should be uploaded to the interface for testing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audioldm_train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
